# Sign Language Recognition Project

## Overview

This project is a **Sign Language Recognition System** developed as part of my final project for the **Data Science and Machine Learning course**. The system aims to recognize and interpret sign language gestures, enabling better communication between sign language users and non-users.

## Features

- Real-time recognition of sign language gestures.
- High accuracy using state-of-the-art machine learning models.
- User-friendly interface for testing and showcasing the results.
- Scalable to support additional gestures and languages.

## Objectives

- Leverage data science techniques to preprocess and analyze sign language datasets.
- Utilize machine learning models to achieve reliable gesture recognition.
- Explore computer vision methods to process video and image data.

## Tools and Technologies

- **Programming Language:** Python
- **Libraries and Frameworks:**
  - TensorFlow / PyTorch (for model training and deployment)
  - OpenCV (for image and video processing)
  - NumPy, Pandas, Matplotlib (for data manipulation and visualization)
  - MediaPipe (for face and hand detection)
- **Development Environment:** Jupyter Notebook

## Dataset

The project uses a curated dataset of sign language gestures, containing:

- Videos of various hand signs.
- Annotations for each gesture.

### Preprocessing Steps:

1. Splitting data into training, validation, and test sets.

## Model

The machine learning model used in this project is a **Convolutional Neural Network (CNN)** for image-based gesture recognition. Key details include:

- **Architecture:** Customized CNN layers optimized for gesture recognition.
- **Evaluation Metrics:** Accuracy, Precision, Recall, and F1-score.

## Results

- Achieved a validation accuracy of **85%**.
- Demonstrated robust real-time performance during live testing.

## Challenges

- Handling variations in lighting and hand orientations.
- Balancing the dataset to ensure equal representation of all gestures.
- Optimizing model performance without sacrificing accuracy.

## Future Improvements

- Expand the dataset to include more gestures and languages.
- Implement advanced models like Transformer-based architectures.
- Develop a mobile application for real-world deployment.

---

## Demo Video
[![Watch the video](https://img.youtube.com/vi/TTGkHIkd984/0.jpg)](https://youtu.be/TTGkHIkd984?si=DEQHpXRTljZBPF5h)

Click the image above to watch a demo of the project in action.


This project showcases the power of machine learning and its potential to break communication barriers. Thank you for taking the time to explore it!

